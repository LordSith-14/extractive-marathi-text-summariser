{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edadffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hardik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "import collections\n",
    "import copy\n",
    "import io\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "stopwords = set()\n",
    "sentences = []\n",
    "sentences_processing = []\n",
    "sentence_dictionary = collections.defaultdict(dict)\n",
    "stemWords = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e68d92f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readStemWords():\n",
    "    '''\n",
    "        Reads the words from the stem words list and transforms the data into usable format\n",
    "     '''\n",
    "    global stemWords\n",
    "    with io.open(\"word_list_marathi.txt\", encoding='utf-8') as textFile:\n",
    "        index = 0\n",
    "        for line in textFile:\n",
    "            line = line.strip()\n",
    "            if len(line) > 0:\n",
    "                index += 1\n",
    "                wordEndIndex = line.find(\">\")\n",
    "                word = line[2:wordEndIndex]\n",
    "                line = line[wordEndIndex + 1:]\n",
    "                baseEndIndex = line.find(\"]\")\n",
    "                base = line[1:baseEndIndex].strip()\n",
    "                line = line[baseEndIndex + 1:]\n",
    "                stem = None\n",
    "                if len(base) >= 0:\n",
    "                    stemEndIndex = base.find('-')\n",
    "                    if stemEndIndex > 0:\n",
    "                        stem = base[:stemEndIndex]\n",
    "\n",
    "                valid = line[line.find(\"(\") + 1: line.find(\")\")].strip()\n",
    "                if valid == \"0\":\n",
    "                    continue\n",
    "                line = line[line.find(\"{\") + 1: line.find(\"}\")].strip()\n",
    "                related = []\n",
    "                if len(line) > 0:\n",
    "                    split = line.split(\",\")\n",
    "                    for s in split:\n",
    "                        related.append(s[:s.find(\"|\")])\n",
    "                if stem == None and len(related) > 0:\n",
    "                    stem = related[0]\n",
    "                if stem != None:\n",
    "                    stemWords[word] = {}\n",
    "                    stemWords[word][\"stem\"] = stem\n",
    "                    stemWords[word][\"related\"] = related\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2aa0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readStopWords():\n",
    "    '''\n",
    "    Reads the stopwords from the file\n",
    "    '''\n",
    "    with io.open(\"stopwords.txt\", encoding='utf-8') as textFile:\n",
    "        for line in textFile:\n",
    "            words = line.lower().strip()\n",
    "            stopwords.add(words)\n",
    "        textFile.close()\n",
    "\n",
    "\n",
    "def removeStopWords(wordlist):\n",
    "    '''\n",
    "    Removes the stopwords from the sentences\n",
    "    :param wordlist: list of stopwords\n",
    "    '''\n",
    "    newlist = []\n",
    "    for word in wordlist:\n",
    "        if word not in stopwords:\n",
    "            newlist.append(word)\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303cb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1db710be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>, {0: ['वर्तमान', 'गटामध्', 'आपलं', 'स्वप्न', 'पूर्ण', 'होणार', 'आहे'], 1: ['आपलं', 'असा', 'परिपूर्ण', 'समुदाय', 'तयार', 'करण्यासाठी', 'आपण', 'सर्वांचं', 'सहयोग', 'कडेच', 'काय', 'करावं', 'लागे']})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    '''\n",
    "    Tokenizes the sentences and words\n",
    "    :param text: text to be tokenized\n",
    "    '''\n",
    "    global sentences, sentences_processing, sentence_dictionary\n",
    "    \n",
    "    # Assuming `sent_tokenize` is imported from NLTK\n",
    "    sentences = sent_tokenize(text)\n",
    "    sentences_processing = copy.deepcopy(sentences)\n",
    "    counter = 0\n",
    "    for sentence in sentences_processing:\n",
    "        sentence = sentence[:-1]\n",
    "        sentence = re.sub(',|\\.|-|\\(|\\)', ' ', sentence)\n",
    "        tokens = sentence.strip().split()\n",
    "#         Assuming removeStopWords and stemmerMarathi functions are defined elsewhere\n",
    "        actualTokens = removeStopWords(tokens)\n",
    "        stemmedTokens = stemmerMarathi(actualTokens)\n",
    "        sentence_dictionary[counter] = stemmedTokens\n",
    "        counter += 1\n",
    "\n",
    "# Example usage\n",
    "text = \"वर्तमान गटामध्ये आपलं स्वप्न पूर्ण होणार आहे. आपलं असा परिपूर्ण समुदाय तयार करण्यासाठी, आपण सर्वांचं सहयोग कडेच कायम करावं लागेल.\"\n",
    "tokenize_text(text)\n",
    "print(sentence_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c40ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "वर्तमान गटामध्ये आपलं स्वप्न पूर्ण आपलं असा परिपूर्ण समुदाय तयार करण्यासाठी आपण सर्वांचं सहयोग कडेच कायम करावं लागेल"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "049a3c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "असा\n"
     ]
    }
   ],
   "source": [
    "def removeCase(word):\n",
    "    '''\n",
    "    :param word: word to be reduced its stem\n",
    "    :return: stem of the word\n",
    "    '''\n",
    "    word_length = len(word) - 1\n",
    "    if word_length > 5:\n",
    "        suffix = \"शया\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "\n",
    "    if word_length > 4:\n",
    "        suffix = \"शे\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"शी\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"चा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ची\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"चे\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"हून\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "\n",
    "    if word_length > 3:\n",
    "        suffix = \"नो\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"तो\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ने\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"नी\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ही\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ते\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"या\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ला\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ना\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ऊण\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "\n",
    "    if word_length > 2:\n",
    "        suffix = \" े\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ी\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"स\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ल\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"त\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"म\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        return word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43659f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNoGender(word):\n",
    "    global stemWords\n",
    "    orig = word\n",
    "    if word in stemWords:\n",
    "        return stemWords[word][\"stem\"]\n",
    "    word_length = len(word) - 1\n",
    "\n",
    "    if word_length > 5:\n",
    "        suffix = \" ुरडा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    if word_length > 4:\n",
    "        suffix = \"ढा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    if word_length > 3:\n",
    "        suffix = \"रु\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"डे\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ती\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ान\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ीण\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"डा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"डी\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"गा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ला\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ळा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"या\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"वा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ये\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"वे\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ती\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    if word_length > 2:\n",
    "        suffix = \"अ\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" े\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"ि \"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ु\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ौ\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ै\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "\n",
    "        suffix = \" ा\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ी\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \" ू\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "        suffix = \"त\"\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "191ddb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmerMarathi(words):\n",
    "    return [removeNoGender(removeCase(word)) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45c60439",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=stemmerMarathi(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9833a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['वर्तमान',\n",
       " 'गटामध्',\n",
       " 'आपलं',\n",
       " 'स्वप्न',\n",
       " 'पूर्ण',\n",
       " 'आपलं',\n",
       " 'असा',\n",
       " 'परिपूर्ण',\n",
       " 'समुदाय',\n",
       " 'तयार',\n",
       " 'करण्यासाठी',\n",
       " 'आपण',\n",
       " 'सर्वांचं',\n",
       " 'सहयोग',\n",
       " 'कडेच',\n",
       " 'काय',\n",
       " 'करावं',\n",
       " 'लागे']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c13331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import copy\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Define global variables (assuming they are defined elsewhere in your code)\n",
    "sentences = []\n",
    "sentences_processing = []\n",
    "sentence_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164e423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb04070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294e36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1665ece8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e8910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466eed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d22e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93cd0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71463d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ab755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220aa11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff3c401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c56c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88b615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92ba45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb3c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5e059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c3a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b6cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a868a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f0ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18a5f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b5279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e385cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feaadb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2832fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b3785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e48b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade23d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac460af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b0462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473d2469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['वर्तमान', 'गटामध्ये', 'आपलं', 'स्वप्न', 'पूर्ण', 'आपलं', 'असा', 'परिपूर्ण', 'समुदाय', 'तयार', 'करण्यासाठी', 'आपण', 'सर्वांचं', 'सहयोग', 'कडेच', 'कायम', 'करावं', 'लागेल']\n"
     ]
    }
   ],
   "source": [
    "# def tokenize_sentence(sentence):\n",
    "#     # Initialize an empty list to store tokens\n",
    "#     tokens = []\n",
    "#     # Initialize a variable to keep track of the start index of the current token\n",
    "#     start = 0\n",
    "    \n",
    "#     # Iterate through each character in the sentence\n",
    "#     for i, char in enumerate(sentence):\n",
    "#         # Check if the current character is a space or punctuation\n",
    "#         if char.isspace() or char in [',', '.', '!', '?', ';', ':']:\n",
    "#             # If the current token is not empty, add it to the list of tokens\n",
    "#             if i > start:\n",
    "#                 tokens.append(sentence[start:i])\n",
    "#             # Update the start index for the next token\n",
    "#             start = i + 1\n",
    "    \n",
    "#     # Handle the last token (if any)\n",
    "#     if start < len(sentence):\n",
    "#         tokens.append(sentence[start:])\n",
    "    \n",
    "#     return tokens\n",
    "\n",
    "# # Example usage\n",
    "# sentence = \"वर्तमान गटामध्ये आपलं स्वप्न पूर्ण आपलं असा परिपूर्ण समुदाय तयार करण्यासाठी आपण सर्वांचं सहयोग कडेच कायम करावं लागेल\"\n",
    "# tokens = tokenize_sentence(sentence)\n",
    "# print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
